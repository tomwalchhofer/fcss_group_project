{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\walchhth\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\walchhth\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (4.12.3)\n",
      "Requirement already satisfied: lxml in c:\\users\\walchhth\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (5.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\walchhth\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\walchhth\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\walchhth\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\walchhth\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\walchhth\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from beautifulsoup4) (2.6)\n"
     ]
    }
   ],
   "source": [
    "#if you still need to install beautifulsoup4\n",
    "\n",
    "! pip install requests beautifulsoup4 lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Basis-URL\n",
    "base_url = \"https://www.ots.at/suche\"\n",
    "\n",
    "# Anfrage-Parameter\n",
    "params = {\n",
    "    \"query\": \"\",\n",
    "    \"seite\": 1,\n",
    "    \"emittentId\": 199,  # Emittent-ID\n",
    "    \"startDate\": 1136934001,  # Startdatum\n",
    "    \"endDate\": 1200092399,    # Enddatum\n",
    "    \"channel\": \"index\",\n",
    "    \"attachment\": \"\"\n",
    "}\n",
    "\n",
    "# Funktion zum Abrufen von Artikeldetails\n",
    "def scrape_article_content(article_url):\n",
    "    try:\n",
    "        response = requests.get(article_url)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Fehler beim Abrufen der Artikel-URL: {article_url}\")\n",
    "            return None, None, None\n",
    "\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        # Titel\n",
    "        title = soup.find(\"h1\").get_text(strip=True)\n",
    "        # Inhalt\n",
    "        content_div = soup.find(\"div\", {\"itemprop\": \"articleBody\"})\n",
    "        content = content_div.get_text(strip=True) if content_div else \"Kein Inhalt verfügbar\"\n",
    "        # Veröffentlichungsdatum\n",
    "        date_meta = soup.find(\"meta\", itemprop=\"datePublished\")\n",
    "        date_time = soup.find(\"time\", {\"itemprop\": \"datePublished\"})\n",
    "        date = (\n",
    "            date_meta[\"content\"] if date_meta and date_meta.has_attr(\"content\") \n",
    "            else date_time[\"datetime\"] if date_time and date_time.has_attr(\"datetime\") \n",
    "            else date_time.get_text(strip=True) if date_time \n",
    "            else \"Kein Datum verfügbar\"\n",
    "        )\n",
    "        return title, content, date\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler beim Abrufen der Details: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "# Funktion zum Scrapen einer Seite\n",
    "def scrape_page(page_number):\n",
    "    params[\"seite\"] = page_number\n",
    "    response = requests.get(base_url, params=params)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Fehler beim Abrufen der Seite {page_number}\")\n",
    "        return []\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    articles = soup.find_all(\"mat-card\")\n",
    "    data = []\n",
    "\n",
    "    for article in articles:\n",
    "        try:\n",
    "            # Titel\n",
    "            title_tag = article.find(\"h1\", class_=\"display-3\")\n",
    "            title = title_tag.get_text(strip=True) if title_tag else \"Kein Titel\"\n",
    "\n",
    "            # Teaser\n",
    "            teaser_tag = article.find(\"p\", class_=\"lead\")\n",
    "            teaser = teaser_tag.get_text(strip=True) if teaser_tag else \"Kein Teaser\"\n",
    "\n",
    "            # Link\n",
    "            link_tag = article.find(\"a\", class_=\"link-detailed-view\")\n",
    "            link = f\"https://www.ots.at{link_tag['href']}\" if link_tag else \"Kein Link\"\n",
    "\n",
    "            # Details scrapen\n",
    "            article_title, article_content, article_date = scrape_article_content(link)\n",
    "\n",
    "            # Daten hinzufügen\n",
    "            data.append({\n",
    "                \"Titel\": title,\n",
    "                \"Teaser\": teaser,\n",
    "                \"Datum\": article_date,\n",
    "                \"Link\": link,\n",
    "                \"Inhalt\": article_content\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler beim Verarbeiten eines Artikels: {e}\")\n",
    "            continue\n",
    "\n",
    "    return data\n",
    "\n",
    "# Hauptfunktion für mehrere Seiten\n",
    "def scrape_all_pages(start_page=1, end_page=5):\n",
    "    all_data = []\n",
    "    for page in range(start_page, end_page + 1):\n",
    "        print(f\"Scraping Seite {page}...\")\n",
    "        page_data = scrape_page(page)\n",
    "        all_data.extend(page_data)\n",
    "        time.sleep(2)  # Wartezeit zwischen Anfragen\n",
    "\n",
    "    return all_data\n",
    "\n",
    "# Ergebnisse speichern\n",
    "def save_to_csv(data, filename=\"ots_scraper_data_spoe_parlament.csv\"):\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(filename, index=False, encoding=\"utf-8\")\n",
    "    print(f\"Daten erfolgreich gespeichert in {filename}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping pages 1 to 100...\n",
      "Scraping Seite 1...\n",
      "Scraping Seite 2...\n",
      "Scraping Seite 3...\n",
      "Scraping Seite 4...\n",
      "Scraping Seite 5...\n",
      "Scraping Seite 6...\n",
      "Scraping Seite 7...\n",
      "Scraping Seite 8...\n",
      "Scraping Seite 9...\n",
      "Scraping Seite 10...\n",
      "Scraping Seite 11...\n",
      "Scraping Seite 12...\n",
      "Scraping Seite 13...\n",
      "Scraping Seite 14...\n",
      "Scraping Seite 15...\n",
      "Scraping Seite 16...\n",
      "Scraping Seite 17...\n",
      "Scraping Seite 18...\n",
      "Scraping Seite 19...\n",
      "Scraping Seite 20...\n",
      "Scraping Seite 21...\n",
      "Scraping Seite 22...\n",
      "Scraping Seite 23...\n",
      "Scraping Seite 24...\n",
      "Scraping Seite 25...\n",
      "Scraping Seite 26...\n",
      "Scraping Seite 27...\n",
      "Scraping Seite 28...\n",
      "Scraping Seite 29...\n",
      "Scraping Seite 30...\n",
      "Scraping Seite 31...\n",
      "Scraping Seite 32...\n",
      "Scraping Seite 33...\n",
      "Scraping Seite 34...\n",
      "Scraping Seite 35...\n",
      "Scraping Seite 36...\n",
      "Scraping Seite 37...\n",
      "Scraping Seite 38...\n",
      "Scraping Seite 39...\n",
      "Scraping Seite 40...\n",
      "Scraping Seite 41...\n",
      "Scraping Seite 42...\n",
      "Scraping Seite 43...\n",
      "Scraping Seite 44...\n",
      "Scraping Seite 45...\n",
      "Scraping Seite 46...\n",
      "Scraping Seite 47...\n",
      "Scraping Seite 48...\n",
      "Scraping Seite 49...\n",
      "Scraping Seite 50...\n",
      "Scraping Seite 51...\n",
      "Scraping Seite 52...\n",
      "Scraping Seite 53...\n",
      "Scraping Seite 54...\n",
      "Scraping Seite 55...\n",
      "Scraping Seite 56...\n",
      "Scraping Seite 57...\n",
      "Scraping Seite 58...\n",
      "Scraping Seite 59...\n",
      "Scraping Seite 60...\n",
      "Scraping Seite 61...\n",
      "Scraping Seite 62...\n",
      "Scraping Seite 63...\n",
      "Scraping Seite 64...\n",
      "Scraping Seite 65...\n",
      "Scraping Seite 66...\n",
      "Scraping Seite 67...\n",
      "Scraping Seite 68...\n",
      "Scraping Seite 69...\n",
      "Scraping Seite 70...\n",
      "Scraping Seite 71...\n",
      "Scraping Seite 72...\n",
      "Scraping Seite 73...\n",
      "Scraping Seite 74...\n",
      "Scraping Seite 75...\n",
      "Scraping Seite 76...\n",
      "Scraping Seite 77...\n",
      "Scraping Seite 78...\n",
      "Scraping Seite 79...\n",
      "Scraping Seite 80...\n",
      "Scraping Seite 81...\n",
      "Scraping Seite 82...\n",
      "Scraping Seite 83...\n",
      "Scraping Seite 84...\n",
      "Scraping Seite 85...\n",
      "Scraping Seite 86...\n",
      "Scraping Seite 87...\n",
      "Scraping Seite 88...\n",
      "Scraping Seite 89...\n",
      "Scraping Seite 90...\n",
      "Scraping Seite 91...\n",
      "Fehler beim Abrufen der Details: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Fehler beim Abrufen der Details: HTTPSConnectionPool(host='www.ots.at', port=443): Max retries exceeded with url: /presseaussendung/OTS_20070913_OTS0246/bayr-fair-play-auch-bei-den-internationalen-arbeitsbedingungen (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002AE40FD9E90>: Failed to resolve 'www.ots.at' ([Errno 11001] getaddrinfo failed)\"))\n",
      "Fehler beim Abrufen der Details: HTTPSConnectionPool(host='www.ots.at', port=443): Max retries exceeded with url: /presseaussendung/OTS_20070913_OTS0242/csoergits-iv-bedauert-selbstverschuldeten-facharbeitermangel (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002AE4150D010>: Failed to resolve 'www.ots.at' ([Errno 11001] getaddrinfo failed)\"))\n",
      "Fehler beim Abrufen der Details: HTTPSConnectionPool(host='www.ots.at', port=443): Max retries exceeded with url: /presseaussendung/OTS_20070913_OTS0205/spoe-tourismussprecherin-trunk-fordert-mehr-kooperation-und-offenheit-bei-der-oesterreich-werbung (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002AE416BF350>: Failed to resolve 'www.ots.at' ([Errno 11001] getaddrinfo failed)\"))\n",
      "Fehler beim Abrufen der Details: HTTPSConnectionPool(host='www.ots.at', port=443): Max retries exceeded with url: /presseaussendung/OTS_20070913_OTS0202/cap-oesterreich-gegen-bedrohung-durch-die-extremisten-gewappnet (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002AE41903350>: Failed to resolve 'www.ots.at' ([Errno 11001] getaddrinfo failed)\"))\n",
      "Fehler beim Abrufen der Details: HTTPSConnectionPool(host='www.ots.at', port=443): Max retries exceeded with url: /presseaussendung/OTS_20070913_OTS0181/scheelebulfon-autos-sollen-ab-2012-deutlich-weniger-co2-ausstossen (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002AE416BE950>: Failed to resolve 'www.ots.at' ([Errno 11001] getaddrinfo failed)\"))\n",
      "Fehler beim Abrufen der Details: HTTPSConnectionPool(host='www.ots.at', port=443): Max retries exceeded with url: /presseaussendung/OTS_20070913_OTS0177/bayr-gentechnik-darf-nicht-ueber-hintertuer-nach-oesterreich-kommen (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002AE44F32F90>: Failed to resolve 'www.ots.at' ([Errno 11001] getaddrinfo failed)\"))\n",
      "Fehler beim Abrufen der Details: HTTPSConnectionPool(host='www.ots.at', port=443): Max retries exceeded with url: /presseaussendung/OTS_20070913_OTS0145/heinisch-hosek-erteilt-rundem-tisch-absage-fristenregelung-muss-ausser-streit-stehen (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002AE4150EF50>: Failed to resolve 'www.ots.at' ([Errno 11001] getaddrinfo failed)\"))\n",
      "Scraping Seite 92...\n",
      "Scraping Seite 93...\n",
      "Scraping Seite 94...\n",
      "Scraping Seite 95...\n",
      "Scraping Seite 96...\n",
      "Scraping Seite 97...\n",
      "Scraping Seite 98...\n",
      "Scraping Seite 99...\n",
      "Scraping Seite 100...\n",
      "Daten erfolgreich gespeichert in ots_scraper_data_spoe_part_1.csv\n",
      "Scraping pages 101 to 200...\n",
      "Scraping Seite 101...\n",
      "Scraping Seite 102...\n",
      "Scraping Seite 103...\n",
      "Scraping Seite 104...\n",
      "Scraping Seite 105...\n",
      "Scraping Seite 106...\n",
      "Scraping Seite 107...\n",
      "Scraping Seite 108...\n",
      "Scraping Seite 109...\n",
      "Scraping Seite 110...\n",
      "Scraping Seite 111...\n",
      "Scraping Seite 112...\n",
      "Scraping Seite 113...\n",
      "Scraping Seite 114...\n",
      "Scraping Seite 115...\n",
      "Scraping Seite 116...\n",
      "Scraping Seite 117...\n",
      "Scraping Seite 118...\n",
      "Scraping Seite 119...\n",
      "Scraping Seite 120...\n",
      "Scraping Seite 121...\n",
      "Scraping Seite 122...\n",
      "Scraping Seite 123...\n",
      "Scraping Seite 124...\n",
      "Scraping Seite 125...\n",
      "Scraping Seite 126...\n",
      "Scraping Seite 127...\n",
      "Scraping Seite 128...\n",
      "Scraping Seite 129...\n",
      "Scraping Seite 130...\n",
      "Scraping Seite 131...\n",
      "Scraping Seite 132...\n",
      "Scraping Seite 133...\n",
      "Scraping Seite 134...\n",
      "Scraping Seite 135...\n",
      "Scraping Seite 136...\n",
      "Scraping Seite 137...\n",
      "Scraping Seite 138...\n",
      "Scraping Seite 139...\n",
      "Scraping Seite 140...\n",
      "Scraping Seite 141...\n",
      "Scraping Seite 142...\n",
      "Scraping Seite 143...\n",
      "Scraping Seite 144...\n",
      "Scraping Seite 145...\n",
      "Scraping Seite 146...\n",
      "Scraping Seite 147...\n",
      "Scraping Seite 148...\n",
      "Scraping Seite 149...\n",
      "Scraping Seite 150...\n",
      "Scraping Seite 151...\n",
      "Scraping Seite 152...\n",
      "Scraping Seite 153...\n",
      "Scraping Seite 154...\n",
      "Scraping Seite 155...\n",
      "Scraping Seite 156...\n",
      "Scraping Seite 157...\n",
      "Scraping Seite 158...\n",
      "Scraping Seite 159...\n",
      "Scraping Seite 160...\n",
      "Scraping Seite 161...\n",
      "Scraping Seite 162...\n",
      "Scraping Seite 163...\n",
      "Scraping Seite 164...\n",
      "Scraping Seite 165...\n",
      "Scraping Seite 166...\n",
      "Scraping Seite 167...\n",
      "Scraping Seite 168...\n",
      "Scraping Seite 169...\n",
      "Scraping Seite 170...\n",
      "Scraping Seite 171...\n",
      "Scraping Seite 172...\n",
      "Scraping Seite 173...\n",
      "Scraping Seite 174...\n",
      "Scraping Seite 175...\n",
      "Scraping Seite 176...\n",
      "Scraping Seite 177...\n",
      "Scraping Seite 178...\n",
      "Scraping Seite 179...\n",
      "Scraping Seite 180...\n",
      "Scraping Seite 181...\n",
      "Scraping Seite 182...\n",
      "Scraping Seite 183...\n",
      "Scraping Seite 184...\n",
      "Scraping Seite 185...\n",
      "Scraping Seite 186...\n",
      "Scraping Seite 187...\n",
      "Scraping Seite 188...\n",
      "Scraping Seite 189...\n",
      "Scraping Seite 190...\n",
      "Scraping Seite 191...\n",
      "Scraping Seite 192...\n",
      "Scraping Seite 193...\n",
      "Scraping Seite 194...\n",
      "Scraping Seite 195...\n",
      "Scraping Seite 196...\n",
      "Scraping Seite 197...\n",
      "Scraping Seite 198...\n",
      "Scraping Seite 199...\n",
      "Scraping Seite 200...\n",
      "Daten erfolgreich gespeichert in ots_scraper_data_spoe_part_2.csv\n",
      "Scraping pages 201 to 300...\n",
      "Scraping Seite 201...\n",
      "Scraping Seite 202...\n",
      "Scraping Seite 203...\n",
      "Scraping Seite 204...\n",
      "Scraping Seite 205...\n",
      "Scraping Seite 206...\n",
      "Scraping Seite 207...\n",
      "Scraping Seite 208...\n",
      "Scraping Seite 209...\n",
      "Scraping Seite 210...\n",
      "Scraping Seite 211...\n",
      "Scraping Seite 212...\n",
      "Scraping Seite 213...\n",
      "Scraping Seite 214...\n",
      "Scraping Seite 215...\n",
      "Scraping Seite 216...\n",
      "Scraping Seite 217...\n",
      "Scraping Seite 218...\n",
      "Scraping Seite 219...\n",
      "Scraping Seite 220...\n",
      "Scraping Seite 221...\n",
      "Scraping Seite 222...\n",
      "Fehler beim Abrufen der Details: 'NoneType' object has no attribute 'get_text'\n",
      "Scraping Seite 223...\n",
      "Scraping Seite 224...\n",
      "Scraping Seite 225...\n",
      "Scraping Seite 226...\n",
      "Scraping Seite 227...\n",
      "Scraping Seite 228...\n",
      "Scraping Seite 229...\n",
      "Scraping Seite 230...\n",
      "Scraping Seite 231...\n",
      "Scraping Seite 232...\n",
      "Scraping Seite 233...\n",
      "Scraping Seite 234...\n",
      "Scraping Seite 235...\n",
      "Scraping Seite 236...\n",
      "Scraping Seite 237...\n",
      "Scraping Seite 238...\n",
      "Scraping Seite 239...\n",
      "Scraping Seite 240...\n",
      "Scraping Seite 241...\n",
      "Scraping Seite 242...\n",
      "Scraping Seite 243...\n",
      "Scraping Seite 244...\n",
      "Scraping Seite 245...\n",
      "Scraping Seite 246...\n",
      "Scraping Seite 247...\n",
      "Scraping Seite 248...\n",
      "Scraping Seite 249...\n",
      "Scraping Seite 250...\n",
      "Scraping Seite 251...\n",
      "Scraping Seite 252...\n",
      "Scraping Seite 253...\n",
      "Scraping Seite 254...\n",
      "Scraping Seite 255...\n",
      "Scraping Seite 256...\n",
      "Scraping Seite 257...\n",
      "Scraping Seite 258...\n",
      "Scraping Seite 259...\n",
      "Scraping Seite 260...\n",
      "Scraping Seite 261...\n",
      "Scraping Seite 262...\n",
      "Scraping Seite 263...\n",
      "Scraping Seite 264...\n",
      "Scraping Seite 265...\n",
      "Scraping Seite 266...\n",
      "Scraping Seite 267...\n",
      "Scraping Seite 268...\n",
      "Scraping Seite 269...\n",
      "Scraping Seite 270...\n",
      "Scraping Seite 271...\n",
      "Scraping Seite 272...\n",
      "Scraping Seite 273...\n",
      "Scraping Seite 274...\n",
      "Scraping Seite 275...\n",
      "Scraping Seite 276...\n",
      "Scraping Seite 277...\n",
      "Scraping Seite 278...\n",
      "Scraping Seite 279...\n",
      "Scraping Seite 280...\n",
      "Scraping Seite 281...\n",
      "Scraping Seite 282...\n",
      "Scraping Seite 283...\n",
      "Scraping Seite 284...\n",
      "Scraping Seite 285...\n",
      "Scraping Seite 286...\n",
      "Scraping Seite 287...\n",
      "Scraping Seite 288...\n",
      "Scraping Seite 289...\n",
      "Scraping Seite 290...\n",
      "Scraping Seite 291...\n",
      "Scraping Seite 292...\n",
      "Scraping Seite 293...\n",
      "Scraping Seite 294...\n",
      "Scraping Seite 295...\n",
      "Scraping Seite 296...\n",
      "Scraping Seite 297...\n",
      "Scraping Seite 298...\n",
      "Scraping Seite 299...\n",
      "Scraping Seite 300...\n",
      "Daten erfolgreich gespeichert in ots_scraper_data_spoe_part_3.csv\n",
      "Scraping pages 301 to 400...\n",
      "Scraping Seite 301...\n",
      "Scraping Seite 302...\n",
      "Scraping Seite 303...\n",
      "Scraping Seite 304...\n",
      "Scraping Seite 305...\n",
      "Scraping Seite 306...\n",
      "Scraping Seite 307...\n",
      "Scraping Seite 308...\n",
      "Scraping Seite 309...\n",
      "Scraping Seite 310...\n",
      "Scraping Seite 311...\n",
      "Scraping Seite 312...\n",
      "Scraping Seite 313...\n",
      "Scraping Seite 314...\n",
      "Scraping Seite 315...\n",
      "Scraping Seite 316...\n",
      "Scraping Seite 317...\n",
      "Scraping Seite 318...\n",
      "Scraping Seite 319...\n",
      "Scraping Seite 320...\n",
      "Scraping Seite 321...\n",
      "Scraping Seite 322...\n",
      "Scraping Seite 323...\n",
      "Scraping Seite 324...\n",
      "Scraping Seite 325...\n",
      "Scraping Seite 326...\n",
      "Scraping Seite 327...\n",
      "Scraping Seite 328...\n",
      "Scraping Seite 329...\n",
      "Scraping Seite 330...\n",
      "Scraping Seite 331...\n",
      "Scraping Seite 332...\n",
      "Scraping Seite 333...\n",
      "Scraping Seite 334...\n",
      "Scraping Seite 335...\n",
      "Scraping Seite 336...\n",
      "Scraping Seite 337...\n",
      "Scraping Seite 338...\n",
      "Scraping Seite 339...\n",
      "Scraping Seite 340...\n",
      "Scraping Seite 341...\n",
      "Scraping Seite 342...\n",
      "Scraping Seite 343...\n",
      "Scraping Seite 344...\n",
      "Scraping Seite 345...\n",
      "Fehler beim Abrufen der Details: 'NoneType' object has no attribute 'get_text'\n",
      "Scraping Seite 346...\n",
      "Scraping Seite 347...\n",
      "Scraping Seite 348...\n",
      "Scraping Seite 349...\n",
      "Scraping Seite 350...\n",
      "Scraping Seite 351...\n",
      "Scraping Seite 352...\n",
      "Scraping Seite 353...\n",
      "Scraping Seite 354...\n",
      "Scraping Seite 355...\n",
      "Scraping Seite 356...\n",
      "Scraping Seite 357...\n",
      "Scraping Seite 358...\n",
      "Scraping Seite 359...\n",
      "Scraping Seite 360...\n",
      "Scraping Seite 361...\n",
      "Scraping Seite 362...\n",
      "Scraping Seite 363...\n",
      "Scraping Seite 364...\n",
      "Scraping Seite 365...\n",
      "Scraping Seite 366...\n",
      "Scraping Seite 367...\n",
      "Scraping Seite 368...\n",
      "Scraping Seite 369...\n",
      "Scraping Seite 370...\n",
      "Scraping Seite 371...\n",
      "Scraping Seite 372...\n",
      "Scraping Seite 373...\n",
      "Scraping Seite 374...\n",
      "Scraping Seite 375...\n",
      "Scraping Seite 376...\n",
      "Scraping Seite 377...\n",
      "Scraping Seite 378...\n",
      "Scraping Seite 379...\n",
      "Scraping Seite 380...\n",
      "Scraping Seite 381...\n",
      "Scraping Seite 382...\n",
      "Scraping Seite 383...\n",
      "Scraping Seite 384...\n",
      "Scraping Seite 385...\n",
      "Scraping Seite 386...\n",
      "Scraping Seite 387...\n",
      "Scraping Seite 388...\n",
      "Scraping Seite 389...\n",
      "Scraping Seite 390...\n",
      "Scraping Seite 391...\n",
      "Scraping Seite 392...\n",
      "Scraping Seite 393...\n",
      "Scraping Seite 394...\n",
      "Scraping Seite 395...\n",
      "Scraping Seite 396...\n",
      "Scraping Seite 397...\n",
      "Scraping Seite 398...\n",
      "Scraping Seite 399...\n",
      "Scraping Seite 400...\n",
      "Daten erfolgreich gespeichert in ots_scraper_data_spoe_part_4.csv\n",
      "Scraping pages 401 to 500...\n",
      "Scraping Seite 401...\n",
      "Scraping Seite 402...\n",
      "Scraping Seite 403...\n",
      "Scraping Seite 404...\n",
      "Scraping Seite 405...\n",
      "Scraping Seite 406...\n",
      "Scraping Seite 407...\n",
      "Scraping Seite 408...\n",
      "Scraping Seite 409...\n",
      "Scraping Seite 410...\n",
      "Scraping Seite 411...\n",
      "Scraping Seite 412...\n",
      "Scraping Seite 413...\n",
      "Scraping Seite 414...\n",
      "Scraping Seite 415...\n",
      "Scraping Seite 416...\n",
      "Scraping Seite 417...\n",
      "Scraping Seite 418...\n",
      "Scraping Seite 419...\n",
      "Scraping Seite 420...\n",
      "Scraping Seite 421...\n",
      "Scraping Seite 422...\n",
      "Scraping Seite 423...\n",
      "Scraping Seite 424...\n",
      "Scraping Seite 425...\n",
      "Scraping Seite 426...\n",
      "Scraping Seite 427...\n",
      "Scraping Seite 428...\n",
      "Scraping Seite 429...\n",
      "Scraping Seite 430...\n",
      "Scraping Seite 431...\n",
      "Scraping Seite 432...\n",
      "Scraping Seite 433...\n",
      "Scraping Seite 434...\n",
      "Scraping Seite 435...\n",
      "Scraping Seite 436...\n",
      "Scraping Seite 437...\n",
      "Scraping Seite 438...\n",
      "Scraping Seite 439...\n",
      "Scraping Seite 440...\n",
      "Scraping Seite 441...\n",
      "Scraping Seite 442...\n",
      "Scraping Seite 443...\n",
      "Scraping Seite 444...\n",
      "Scraping Seite 445...\n",
      "Scraping Seite 446...\n",
      "Scraping Seite 447...\n",
      "Scraping Seite 448...\n",
      "Scraping Seite 449...\n",
      "Scraping Seite 450...\n",
      "Scraping Seite 451...\n",
      "Scraping Seite 452...\n",
      "Scraping Seite 453...\n",
      "Scraping Seite 454...\n",
      "Scraping Seite 455...\n",
      "Scraping Seite 456...\n",
      "Scraping Seite 457...\n",
      "Scraping Seite 458...\n",
      "Scraping Seite 459...\n",
      "Scraping Seite 460...\n",
      "Scraping Seite 461...\n",
      "Scraping Seite 462...\n",
      "Scraping Seite 463...\n",
      "Scraping Seite 464...\n",
      "Scraping Seite 465...\n",
      "Scraping Seite 466...\n",
      "Scraping Seite 467...\n",
      "Scraping Seite 468...\n",
      "Scraping Seite 469...\n",
      "Scraping Seite 470...\n",
      "Scraping Seite 471...\n",
      "Scraping Seite 472...\n",
      "Scraping Seite 473...\n",
      "Scraping Seite 474...\n",
      "Scraping Seite 475...\n",
      "Scraping Seite 476...\n",
      "Scraping Seite 477...\n",
      "Scraping Seite 478...\n",
      "Scraping Seite 479...\n",
      "Scraping Seite 480...\n",
      "Scraping Seite 481...\n",
      "Scraping Seite 482...\n",
      "Scraping Seite 483...\n",
      "Scraping Seite 484...\n",
      "Scraping Seite 485...\n",
      "Scraping Seite 486...\n",
      "Scraping Seite 487...\n",
      "Scraping Seite 488...\n",
      "Scraping Seite 489...\n",
      "Scraping Seite 490...\n",
      "Scraping Seite 491...\n",
      "Scraping Seite 492...\n",
      "Scraping Seite 493...\n",
      "Scraping Seite 494...\n",
      "Scraping Seite 495...\n",
      "Scraping Seite 496...\n",
      "Scraping Seite 497...\n",
      "Scraping Seite 498...\n",
      "Scraping Seite 499...\n",
      "Scraping Seite 500...\n",
      "Daten erfolgreich gespeichert in ots_scraper_data_spoe_part_5.csv\n",
      "Scraping pages 501 to 600...\n",
      "Scraping Seite 501...\n",
      "Scraping Seite 502...\n",
      "Scraping Seite 503...\n",
      "Scraping Seite 504...\n",
      "Scraping Seite 505...\n",
      "Scraping Seite 506...\n",
      "Scraping Seite 507...\n",
      "Scraping Seite 508...\n",
      "Scraping Seite 509...\n",
      "Scraping Seite 510...\n",
      "Scraping Seite 511...\n",
      "Scraping Seite 512...\n",
      "Scraping Seite 513...\n",
      "Scraping Seite 514...\n",
      "Scraping Seite 515...\n",
      "Scraping Seite 516...\n",
      "Scraping Seite 517...\n",
      "Scraping Seite 518...\n",
      "Scraping Seite 519...\n",
      "Fehler beim Abrufen der Details: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Scraping Seite 520...\n",
      "Scraping Seite 521...\n",
      "Scraping Seite 522...\n",
      "Scraping Seite 523...\n",
      "Scraping Seite 524...\n",
      "Scraping Seite 525...\n",
      "Scraping Seite 526...\n",
      "Scraping Seite 527...\n",
      "Scraping Seite 528...\n",
      "Scraping Seite 529...\n",
      "Scraping Seite 530...\n",
      "Scraping Seite 531...\n",
      "Scraping Seite 532...\n",
      "Scraping Seite 533...\n",
      "Scraping Seite 534...\n",
      "Scraping Seite 535...\n",
      "Scraping Seite 536...\n",
      "Scraping Seite 537...\n",
      "Scraping Seite 538...\n",
      "Scraping Seite 539...\n",
      "Scraping Seite 540...\n",
      "Scraping Seite 541...\n",
      "Scraping Seite 542...\n",
      "Scraping Seite 543...\n",
      "Scraping Seite 544...\n",
      "Scraping Seite 545...\n",
      "Scraping Seite 546...\n",
      "Scraping Seite 547...\n",
      "Scraping Seite 548...\n",
      "Scraping Seite 549...\n",
      "Scraping Seite 550...\n",
      "Scraping Seite 551...\n",
      "Scraping Seite 552...\n",
      "Scraping Seite 553...\n",
      "Scraping Seite 554...\n",
      "Scraping Seite 555...\n",
      "Scraping Seite 556...\n",
      "Scraping Seite 557...\n",
      "Scraping Seite 558...\n",
      "Scraping Seite 559...\n",
      "Scraping Seite 560...\n",
      "Scraping Seite 561...\n",
      "Scraping Seite 562...\n",
      "Scraping Seite 563...\n",
      "Scraping Seite 564...\n",
      "Fehler beim Abrufen der Details: 'NoneType' object has no attribute 'get_text'\n",
      "Scraping Seite 565...\n",
      "Scraping Seite 566...\n",
      "Scraping Seite 567...\n",
      "Scraping Seite 568...\n",
      "Scraping Seite 569...\n",
      "Scraping Seite 570...\n",
      "Scraping Seite 571...\n",
      "Scraping Seite 572...\n",
      "Scraping Seite 573...\n",
      "Scraping Seite 574...\n",
      "Scraping Seite 575...\n",
      "Scraping Seite 576...\n",
      "Scraping Seite 577...\n",
      "Scraping Seite 578...\n",
      "Scraping Seite 579...\n",
      "Scraping Seite 580...\n",
      "Scraping Seite 581...\n",
      "Scraping Seite 582...\n",
      "Scraping Seite 583...\n",
      "Scraping Seite 584...\n",
      "Scraping Seite 585...\n",
      "Scraping Seite 586...\n",
      "Scraping Seite 587...\n",
      "Scraping Seite 588...\n",
      "Scraping Seite 589...\n",
      "Scraping Seite 590...\n",
      "Scraping Seite 591...\n",
      "Scraping Seite 592...\n",
      "Scraping Seite 593...\n",
      "Scraping Seite 594...\n",
      "Scraping Seite 595...\n",
      "Scraping Seite 596...\n",
      "Scraping Seite 597...\n",
      "Scraping Seite 598...\n",
      "Scraping Seite 599...\n",
      "Scraping Seite 600...\n",
      "Daten erfolgreich gespeichert in ots_scraper_data_spoe_part_6.csv\n",
      "Scraping pages 601 to 700...\n",
      "Scraping Seite 601...\n",
      "Scraping Seite 602...\n",
      "Scraping Seite 603...\n",
      "Scraping Seite 604...\n",
      "Scraping Seite 605...\n",
      "Scraping Seite 606...\n",
      "Scraping Seite 607...\n",
      "Scraping Seite 608...\n",
      "Scraping Seite 609...\n",
      "Scraping Seite 610...\n",
      "Scraping Seite 611...\n",
      "Scraping Seite 612...\n",
      "Scraping Seite 613...\n",
      "Scraping Seite 614...\n",
      "Scraping Seite 615...\n",
      "Scraping Seite 616...\n",
      "Scraping Seite 617...\n",
      "Scraping Seite 618...\n",
      "Scraping Seite 619...\n",
      "Scraping Seite 620...\n",
      "Scraping Seite 621...\n",
      "Scraping Seite 622...\n",
      "Scraping Seite 623...\n",
      "Scraping Seite 624...\n",
      "Scraping Seite 625...\n",
      "Scraping Seite 626...\n",
      "Scraping Seite 627...\n",
      "Scraping Seite 628...\n",
      "Scraping Seite 629...\n",
      "Scraping Seite 630...\n",
      "Scraping Seite 631...\n",
      "Scraping Seite 632...\n",
      "Scraping Seite 633...\n",
      "Scraping Seite 634...\n",
      "Scraping Seite 635...\n",
      "Scraping Seite 636...\n",
      "Scraping Seite 637...\n",
      "Fehler beim Abrufen der Details: 'NoneType' object has no attribute 'get_text'\n",
      "Scraping Seite 638...\n",
      "Scraping Seite 639...\n",
      "Scraping Seite 640...\n",
      "Scraping Seite 641...\n",
      "Scraping Seite 642...\n",
      "Scraping Seite 643...\n",
      "Scraping Seite 644...\n",
      "Scraping Seite 645...\n",
      "Scraping Seite 646...\n",
      "Scraping Seite 647...\n",
      "Scraping Seite 648...\n",
      "Scraping Seite 649...\n",
      "Scraping Seite 650...\n",
      "Scraping Seite 651...\n",
      "Scraping Seite 652...\n",
      "Scraping Seite 653...\n",
      "Scraping Seite 654...\n",
      "Scraping Seite 655...\n",
      "Scraping Seite 656...\n",
      "Scraping Seite 657...\n",
      "Scraping Seite 658...\n",
      "Scraping Seite 659...\n",
      "Scraping Seite 660...\n",
      "Scraping Seite 661...\n",
      "Scraping Seite 662...\n",
      "Scraping Seite 663...\n",
      "Scraping Seite 664...\n",
      "Scraping Seite 665...\n",
      "Scraping Seite 666...\n",
      "Scraping Seite 667...\n",
      "Scraping Seite 668...\n",
      "Scraping Seite 669...\n",
      "Scraping Seite 670...\n",
      "Scraping Seite 671...\n",
      "Scraping Seite 672...\n",
      "Scraping Seite 673...\n",
      "Scraping Seite 674...\n",
      "Scraping Seite 675...\n",
      "Scraping Seite 676...\n",
      "Scraping Seite 677...\n",
      "Scraping Seite 678...\n",
      "Scraping Seite 679...\n",
      "Scraping Seite 680...\n",
      "Scraping Seite 681...\n",
      "Scraping Seite 682...\n",
      "Scraping Seite 683...\n",
      "Scraping Seite 684...\n",
      "Scraping Seite 685...\n",
      "Scraping Seite 686...\n",
      "Scraping Seite 687...\n",
      "Scraping Seite 688...\n",
      "Scraping Seite 689...\n",
      "Scraping Seite 690...\n",
      "Scraping Seite 691...\n",
      "Scraping Seite 692...\n",
      "Scraping Seite 693...\n",
      "Scraping Seite 694...\n",
      "Scraping Seite 695...\n",
      "Scraping Seite 696...\n",
      "Scraping Seite 697...\n",
      "Scraping Seite 698...\n",
      "Scraping Seite 699...\n",
      "Scraping Seite 700...\n",
      "Daten erfolgreich gespeichert in ots_scraper_data_spoe_part_7.csv\n",
      "Scraping pages 701 to 800...\n",
      "Scraping Seite 701...\n",
      "Scraping Seite 702...\n",
      "Scraping Seite 703...\n",
      "Scraping Seite 704...\n",
      "Scraping Seite 705...\n",
      "Scraping Seite 706...\n",
      "Scraping Seite 707...\n",
      "Scraping Seite 708...\n",
      "Scraping Seite 709...\n",
      "Scraping Seite 710...\n",
      "Scraping Seite 711...\n",
      "Scraping Seite 712...\n",
      "Scraping Seite 713...\n",
      "Scraping Seite 714...\n",
      "Scraping Seite 715...\n",
      "Scraping Seite 716...\n",
      "Scraping Seite 717...\n",
      "Scraping Seite 718...\n",
      "Scraping Seite 719...\n",
      "Scraping Seite 720...\n",
      "Scraping Seite 721...\n",
      "Scraping Seite 722...\n",
      "Scraping Seite 723...\n",
      "Scraping Seite 724...\n",
      "Scraping Seite 725...\n",
      "Scraping Seite 726...\n",
      "Scraping Seite 727...\n",
      "Scraping Seite 728...\n",
      "Scraping Seite 729...\n",
      "Scraping Seite 730...\n",
      "Scraping Seite 731...\n",
      "Scraping Seite 732...\n",
      "Scraping Seite 733...\n",
      "Scraping Seite 734...\n",
      "Scraping Seite 735...\n",
      "Scraping Seite 736...\n",
      "Scraping Seite 737...\n",
      "Scraping Seite 738...\n",
      "Scraping Seite 739...\n",
      "Scraping Seite 740...\n",
      "Scraping Seite 741...\n",
      "Scraping Seite 742...\n",
      "Scraping Seite 743...\n",
      "Scraping Seite 744...\n",
      "Scraping Seite 745...\n",
      "Scraping Seite 746...\n",
      "Scraping Seite 747...\n",
      "Scraping Seite 748...\n",
      "Scraping Seite 749...\n",
      "Scraping Seite 750...\n",
      "Scraping Seite 751...\n",
      "Scraping Seite 752...\n",
      "Scraping Seite 753...\n",
      "Scraping Seite 754...\n",
      "Scraping Seite 755...\n",
      "Scraping Seite 756...\n",
      "Scraping Seite 757...\n",
      "Scraping Seite 758...\n",
      "Scraping Seite 759...\n",
      "Scraping Seite 760...\n",
      "Scraping Seite 761...\n",
      "Scraping Seite 762...\n",
      "Scraping Seite 763...\n",
      "Scraping Seite 764...\n",
      "Scraping Seite 765...\n",
      "Scraping Seite 766...\n",
      "Scraping Seite 767...\n",
      "Scraping Seite 768...\n",
      "Scraping Seite 769...\n",
      "Scraping Seite 770...\n",
      "Scraping Seite 771...\n",
      "Scraping Seite 772...\n",
      "Scraping Seite 773...\n",
      "Scraping Seite 774...\n",
      "Scraping Seite 775...\n",
      "Scraping Seite 776...\n",
      "Scraping Seite 777...\n",
      "Scraping Seite 778...\n",
      "Scraping Seite 779...\n",
      "Scraping Seite 780...\n",
      "Scraping Seite 781...\n",
      "Scraping Seite 782...\n",
      "Scraping Seite 783...\n",
      "Scraping Seite 784...\n",
      "Scraping Seite 785...\n",
      "Scraping Seite 786...\n",
      "Scraping Seite 787...\n",
      "Scraping Seite 788...\n",
      "Scraping Seite 789...\n",
      "Scraping Seite 790...\n",
      "Scraping Seite 791...\n",
      "Scraping Seite 792...\n",
      "Scraping Seite 793...\n",
      "Scraping Seite 794...\n",
      "Scraping Seite 795...\n",
      "Scraping Seite 796...\n",
      "Scraping Seite 797...\n",
      "Scraping Seite 798...\n",
      "Scraping Seite 799...\n",
      "Scraping Seite 800...\n",
      "Keine Daten gescrapt für Seiten 701 bis 800.\n",
      "Scraping pages 801 to 900...\n",
      "Scraping Seite 801...\n",
      "Scraping Seite 802...\n",
      "Scraping Seite 803...\n",
      "Scraping Seite 804...\n",
      "Scraping Seite 805...\n",
      "Scraping Seite 806...\n",
      "Scraping Seite 807...\n",
      "Scraping Seite 808...\n",
      "Scraping Seite 809...\n",
      "Scraping Seite 810...\n",
      "Scraping Seite 811...\n",
      "Scraping Seite 812...\n",
      "Scraping Seite 813...\n",
      "Scraping Seite 814...\n",
      "Scraping Seite 815...\n",
      "Scraping Seite 816...\n",
      "Scraping Seite 817...\n",
      "Scraping Seite 818...\n",
      "Scraping Seite 819...\n",
      "Scraping Seite 820...\n",
      "Scraping Seite 821...\n",
      "Scraping Seite 822...\n",
      "Scraping Seite 823...\n",
      "Scraping Seite 824...\n",
      "Scraping Seite 825...\n",
      "Scraping Seite 826...\n",
      "Scraping Seite 827...\n",
      "Scraping Seite 828...\n",
      "Scraping Seite 829...\n",
      "Scraping Seite 830...\n",
      "Scraping Seite 831...\n",
      "Scraping Seite 832...\n",
      "Scraping Seite 833...\n",
      "Scraping Seite 834...\n",
      "Scraping Seite 835...\n",
      "Scraping Seite 836...\n",
      "Scraping Seite 837...\n",
      "Scraping Seite 838...\n",
      "Scraping Seite 839...\n",
      "Scraping Seite 840...\n",
      "Scraping Seite 841...\n",
      "Scraping Seite 842...\n",
      "Scraping Seite 843...\n",
      "Scraping Seite 844...\n",
      "Scraping Seite 845...\n",
      "Scraping Seite 846...\n",
      "Scraping Seite 847...\n",
      "Scraping Seite 848...\n",
      "Scraping Seite 849...\n",
      "Scraping Seite 850...\n",
      "Scraping Seite 851...\n",
      "Scraping Seite 852...\n",
      "Scraping Seite 853...\n",
      "Scraping Seite 854...\n",
      "Scraping Seite 855...\n",
      "Scraping Seite 856...\n",
      "Scraping Seite 857...\n",
      "Scraping Seite 858...\n",
      "Scraping Seite 859...\n",
      "Scraping Seite 860...\n",
      "Scraping Seite 861...\n",
      "Scraping Seite 862...\n",
      "Scraping Seite 863...\n",
      "Scraping Seite 864...\n",
      "Scraping Seite 865...\n",
      "Scraping Seite 866...\n",
      "Scraping Seite 867...\n",
      "Scraping Seite 868...\n",
      "Scraping Seite 869...\n",
      "Scraping Seite 870...\n",
      "Scraping Seite 871...\n",
      "Scraping Seite 872...\n",
      "Scraping Seite 873...\n",
      "Scraping Seite 874...\n",
      "Scraping Seite 875...\n",
      "Scraping Seite 876...\n",
      "Scraping Seite 877...\n",
      "Scraping Seite 878...\n",
      "Scraping Seite 879...\n",
      "Scraping Seite 880...\n",
      "Scraping Seite 881...\n",
      "Scraping Seite 882...\n",
      "Scraping Seite 883...\n",
      "Scraping Seite 884...\n",
      "Scraping Seite 885...\n",
      "Scraping Seite 886...\n",
      "Scraping Seite 887...\n",
      "Scraping Seite 888...\n",
      "Scraping Seite 889...\n",
      "Scraping Seite 890...\n",
      "Scraping Seite 891...\n",
      "Scraping Seite 892...\n",
      "Scraping Seite 893...\n",
      "Scraping Seite 894...\n",
      "Scraping Seite 895...\n",
      "Scraping Seite 896...\n",
      "Scraping Seite 897...\n",
      "Scraping Seite 898...\n",
      "Scraping Seite 899...\n",
      "Scraping Seite 900...\n",
      "Keine Daten gescrapt für Seiten 801 bis 900.\n"
     ]
    }
   ],
   "source": [
    "# Ausführung: Scrape data in steps\n",
    "for i in range(9):  # Adjust the range as needed to cover all steps\n",
    "    x = i * 100  # Calculate the starting page for this iteration\n",
    "    if __name__ == \"__main__\":\n",
    "        print(f\"Scraping pages {x + 1} to {x + 100}...\")\n",
    "        scraped_data = scrape_all_pages(start_page=x + 1, end_page=x + 100)  \n",
    "        if scraped_data:\n",
    "            # Save to a unique file for each iteration\n",
    "            filename = f\"ots_scraper_data_spoe_parlament_part_{i + 1}.csv\"\n",
    "            save_to_csv(scraped_data, filename)\n",
    "        else:\n",
    "            print(f\"Keine Daten gescrapt für Seiten {x + 1} bis {x + 100}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titel</th>\n",
       "      <th>Teaser</th>\n",
       "      <th>Datum</th>\n",
       "      <th>Link</th>\n",
       "      <th>Inhalt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Muttonen: Kein Ende der Seipel-Skandale</td>\n",
       "      <td>Gehrer und Seipel schaden Ansehen der Kulturna...</td>\n",
       "      <td>2006-03-08T15:37:10+01:00</td>\n",
       "      <td>https://www.ots.at/presseaussendung/OTS_200603...</td>\n",
       "      <td>Gehrer und Seipel schaden Ansehen der Kulturna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Matznetter zu Mittelstandstrategie der Regieru...</td>\n",
       "      <td>\"Mini-Wahlzuckerln nach sechs Jahren Regieren ...</td>\n",
       "      <td>2006-03-08T14:46:48+01:00</td>\n",
       "      <td>https://www.ots.at/presseaussendung/OTS_200603...</td>\n",
       "      <td>\"Mini-Wahlzuckerln nach sechs Jahren Regieren ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Morgen Donnerstag: Habermas/Gusenbauer/Swoboda...</td>\n",
       "      <td>Wien (SK) - Das Renner-Institut, die Bildungso...</td>\n",
       "      <td>2006-03-08T14:40:13+01:00</td>\n",
       "      <td>https://www.ots.at/presseaussendung/OTS_200603...</td>\n",
       "      <td>Wien (SK) - Das Renner-Institut, die Bildungso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Riepl unterstützt Matznetter-Vorschlag</td>\n",
       "      <td>Finanzämter sollen zu viel bezahle Steuern aut...</td>\n",
       "      <td>2006-03-08T14:35:30+01:00</td>\n",
       "      <td>https://www.ots.at/presseaussendung/OTS_200603...</td>\n",
       "      <td>Finanzämter sollen zu viel bezahle Steuern aut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gusenbauer: Bahnachse nach Südösterreich unver...</td>\n",
       "      <td>SPÖ-Chef bei 102. \"Startklar\"-Tag in Wolfsberg</td>\n",
       "      <td>2006-03-08T14:26:33+01:00</td>\n",
       "      <td>https://www.ots.at/presseaussendung/OTS_200603...</td>\n",
       "      <td>SPÖ-Chef bei 102. \"Startklar\"-Tag in Wolfsberg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>Bures zu Neujahrskonferenz: Intensive politisc...</td>\n",
       "      <td>Wien (SK) - Nach dem erfolgreichen Start ins W...</td>\n",
       "      <td>2006-01-11T12:00:51+01:00</td>\n",
       "      <td>https://www.ots.at/presseaussendung/OTS_200601...</td>\n",
       "      <td>Wien (SK) - Nach dem erfolgreichen Start ins W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>Audio-OTS von Bures/Darabos auf www.spoe.at</td>\n",
       "      <td>Wien (SK) - Der SPÖ-Pressedienst stellt in Kür...</td>\n",
       "      <td>2006-01-11T11:38:19+01:00</td>\n",
       "      <td>https://www.ots.at/presseaussendung/OTS_200601...</td>\n",
       "      <td>Wien (SK) - Der SPÖ-Pressedienst stellt in Kür...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>Parnigoni: Kriminalitätsstatistik 2005 ist Leh...</td>\n",
       "      <td>\"Nicht Mogeln und Schönfärben, Frau Minister!\"</td>\n",
       "      <td>2006-01-11T11:31:05+01:00</td>\n",
       "      <td>https://www.ots.at/presseaussendung/OTS_200601...</td>\n",
       "      <td>\"Nicht Mogeln und Schönfärben, Frau Minister!\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>Prammer: Hohe Teilzeitquote bei Frauen Ausdruc...</td>\n",
       "      <td>Frauen brauchen Arbeit, von der sie leben können</td>\n",
       "      <td>2006-01-11T11:13:29+01:00</td>\n",
       "      <td>https://www.ots.at/presseaussendung/OTS_200601...</td>\n",
       "      <td>Frauen brauchen Arbeit, von der sie leben könn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>H e u t e : Bures/Darabos - Pressekonferenz um...</td>\n",
       "      <td>Wien (SK) - Heute Mittwoch, 11. Jänner 2006, f...</td>\n",
       "      <td>2006-01-11T09:32:58+01:00</td>\n",
       "      <td>https://www.ots.at/presseaussendung/OTS_200601...</td>\n",
       "      <td>Wien (SK) - Heute Mittwoch, 11. Jänner 2006, f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>818 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Titel  \\\n",
       "0              Muttonen: Kein Ende der Seipel-Skandale   \n",
       "1    Matznetter zu Mittelstandstrategie der Regieru...   \n",
       "2    Morgen Donnerstag: Habermas/Gusenbauer/Swoboda...   \n",
       "3               Riepl unterstützt Matznetter-Vorschlag   \n",
       "4    Gusenbauer: Bahnachse nach Südösterreich unver...   \n",
       "..                                                 ...   \n",
       "813  Bures zu Neujahrskonferenz: Intensive politisc...   \n",
       "814        Audio-OTS von Bures/Darabos auf www.spoe.at   \n",
       "815  Parnigoni: Kriminalitätsstatistik 2005 ist Leh...   \n",
       "816  Prammer: Hohe Teilzeitquote bei Frauen Ausdruc...   \n",
       "817  H e u t e : Bures/Darabos - Pressekonferenz um...   \n",
       "\n",
       "                                                Teaser  \\\n",
       "0    Gehrer und Seipel schaden Ansehen der Kulturna...   \n",
       "1    \"Mini-Wahlzuckerln nach sechs Jahren Regieren ...   \n",
       "2    Wien (SK) - Das Renner-Institut, die Bildungso...   \n",
       "3    Finanzämter sollen zu viel bezahle Steuern aut...   \n",
       "4       SPÖ-Chef bei 102. \"Startklar\"-Tag in Wolfsberg   \n",
       "..                                                 ...   \n",
       "813  Wien (SK) - Nach dem erfolgreichen Start ins W...   \n",
       "814  Wien (SK) - Der SPÖ-Pressedienst stellt in Kür...   \n",
       "815     \"Nicht Mogeln und Schönfärben, Frau Minister!\"   \n",
       "816   Frauen brauchen Arbeit, von der sie leben können   \n",
       "817  Wien (SK) - Heute Mittwoch, 11. Jänner 2006, f...   \n",
       "\n",
       "                         Datum  \\\n",
       "0    2006-03-08T15:37:10+01:00   \n",
       "1    2006-03-08T14:46:48+01:00   \n",
       "2    2006-03-08T14:40:13+01:00   \n",
       "3    2006-03-08T14:35:30+01:00   \n",
       "4    2006-03-08T14:26:33+01:00   \n",
       "..                         ...   \n",
       "813  2006-01-11T12:00:51+01:00   \n",
       "814  2006-01-11T11:38:19+01:00   \n",
       "815  2006-01-11T11:31:05+01:00   \n",
       "816  2006-01-11T11:13:29+01:00   \n",
       "817  2006-01-11T09:32:58+01:00   \n",
       "\n",
       "                                                  Link  \\\n",
       "0    https://www.ots.at/presseaussendung/OTS_200603...   \n",
       "1    https://www.ots.at/presseaussendung/OTS_200603...   \n",
       "2    https://www.ots.at/presseaussendung/OTS_200603...   \n",
       "3    https://www.ots.at/presseaussendung/OTS_200603...   \n",
       "4    https://www.ots.at/presseaussendung/OTS_200603...   \n",
       "..                                                 ...   \n",
       "813  https://www.ots.at/presseaussendung/OTS_200601...   \n",
       "814  https://www.ots.at/presseaussendung/OTS_200601...   \n",
       "815  https://www.ots.at/presseaussendung/OTS_200601...   \n",
       "816  https://www.ots.at/presseaussendung/OTS_200601...   \n",
       "817  https://www.ots.at/presseaussendung/OTS_200601...   \n",
       "\n",
       "                                                Inhalt  \n",
       "0    Gehrer und Seipel schaden Ansehen der Kulturna...  \n",
       "1    \"Mini-Wahlzuckerln nach sechs Jahren Regieren ...  \n",
       "2    Wien (SK) - Das Renner-Institut, die Bildungso...  \n",
       "3    Finanzämter sollen zu viel bezahle Steuern aut...  \n",
       "4    SPÖ-Chef bei 102. \"Startklar\"-Tag in Wolfsberg...  \n",
       "..                                                 ...  \n",
       "813  Wien (SK) - Nach dem erfolgreichen Start ins W...  \n",
       "814  Wien (SK) - Der SPÖ-Pressedienst stellt in Kür...  \n",
       "815  \"Nicht Mogeln und Schönfärben, Frau Minister!\"...  \n",
       "816  Frauen brauchen Arbeit, von der sie leben könn...  \n",
       "817  Wien (SK) - Heute Mittwoch, 11. Jänner 2006, f...  \n",
       "\n",
       "[818 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_spoe = pd.read_csv(\"ots_scraper_data_spoe_parlament_part_7.csv\")\n",
    "\n",
    "display(df_spoe)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verarbeite Datei: c:\\Users\\walchhth\\OneDrive - Styria-IT Solutions GmbH & Co KG\\Dokumente\\KLZ - TOM\\CSS - Master\\1. Semester\\Foundations of CSS\\Group_Project\\ots_scraper_data_spoe_part_1.csv\n",
      "Verarbeite Datei: c:\\Users\\walchhth\\OneDrive - Styria-IT Solutions GmbH & Co KG\\Dokumente\\KLZ - TOM\\CSS - Master\\1. Semester\\Foundations of CSS\\Group_Project\\ots_scraper_data_spoe_part_2.csv\n",
      "Verarbeite Datei: c:\\Users\\walchhth\\OneDrive - Styria-IT Solutions GmbH & Co KG\\Dokumente\\KLZ - TOM\\CSS - Master\\1. Semester\\Foundations of CSS\\Group_Project\\ots_scraper_data_spoe_part_3.csv\n",
      "Verarbeite Datei: c:\\Users\\walchhth\\OneDrive - Styria-IT Solutions GmbH & Co KG\\Dokumente\\KLZ - TOM\\CSS - Master\\1. Semester\\Foundations of CSS\\Group_Project\\ots_scraper_data_spoe_part_4.csv\n",
      "Verarbeite Datei: c:\\Users\\walchhth\\OneDrive - Styria-IT Solutions GmbH & Co KG\\Dokumente\\KLZ - TOM\\CSS - Master\\1. Semester\\Foundations of CSS\\Group_Project\\ots_scraper_data_spoe_part_5.csv\n",
      "Verarbeite Datei: c:\\Users\\walchhth\\OneDrive - Styria-IT Solutions GmbH & Co KG\\Dokumente\\KLZ - TOM\\CSS - Master\\1. Semester\\Foundations of CSS\\Group_Project\\ots_scraper_data_spoe_part_6.csv\n",
      "Verarbeite Datei: c:\\Users\\walchhth\\OneDrive - Styria-IT Solutions GmbH & Co KG\\Dokumente\\KLZ - TOM\\CSS - Master\\1. Semester\\Foundations of CSS\\Group_Project\\ots_scraper_data_spoe_part_7.csv\n",
      "Alle Dateien erfolgreich kombiniert in: ots_scraper_data_spoe_combined.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Name der Ausgabe-Datei\n",
    "output_filename = \"ots_scraper_data_spoe_parlament.csv\"\n",
    "\n",
    "def combine_csv_files(output_filename):\n",
    "    # Aktuelles Verzeichnis des Notebooks\n",
    "    current_directory = os.getcwd()\n",
    "\n",
    "    # Liste, um alle DataFrames zu speichern\n",
    "    all_data = []\n",
    "\n",
    "    # Iteriere durch alle Dateien im aktuellen Verzeichnis\n",
    "    for filename in os.listdir(current_directory):\n",
    "        if filename.startswith(\"ots_scraper_data_spoe_parlament_part_\") and filename.endswith(\".csv\"):\n",
    "            file_path = os.path.join(current_directory, filename)\n",
    "            print(f\"Verarbeite Datei: {file_path}\")\n",
    "            # Lade die CSV-Datei und füge sie zur Liste hinzu\n",
    "            df = pd.read_csv(file_path)\n",
    "            all_data.append(df)\n",
    "\n",
    "    # Kombiniere alle DataFrames in ein einziges DataFrame\n",
    "    if all_data:\n",
    "        combined_df = pd.concat(all_data, ignore_index=True)\n",
    "        # Speichere das kombinierte DataFrame in einer neuen CSV-Datei\n",
    "        combined_df.to_csv(output_filename, index=False, encoding=\"utf-8\")\n",
    "        print(f\"Alle Dateien erfolgreich kombiniert in: {output_filename}\")\n",
    "    else:\n",
    "        print(\"Keine Dateien gefunden, die kombiniert werden können.\")\n",
    "\n",
    "# Funktion ausführen\n",
    "combine_csv_files(output_filename)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
